{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.04: Predicting Boston House Prices with Regularization\n",
    "\n",
    "In this exercise, you will build a neural network that will predict the median house price for a suburb in Boston and see how to add regularizers to a network.\n",
    "\n",
    "The dataset is composed of 12 different features that provide information about the suburb and a target variable (MEDV). The target variable is numeric and represents the median value of owner-occupied homes in units of \\$1,000.\n",
    "\n",
    "The following steps will help you complete the exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Import the pandas package as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Create a `file_url` variable containing a link to the raw dataset. Use the `data/boston_house_price.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Load the dataset into a variable called `df` using `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Display the first five rows using `.head()`\n",
    "\n",
    "Output:\n",
    "\n",
    "![Figure 6.15](img/fig6_15.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Extract the target variable using `.pop()` and save it into a variable called `label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Import the `scale` function from `sklearn.preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Scale the DataFrame, `df`, and save the results into a variable called `scaled_features`. Print its content\n",
    "\n",
    "```\n",
    "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -0.66660821,\n",
    "        -1.45900038, -1.0755623 ],\n",
    "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.98732948,\n",
    "        -0.30309415, -0.49243937],\n",
    "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.98732948,\n",
    "        -0.30309415, -1.2087274 ],\n",
    "       ...,\n",
    "       [-0.41344658, -0.48772236,  0.11573841, ..., -0.80321172,\n",
    "         1.17646583, -0.98304761],\n",
    "       [-0.40776407, -0.48772236,  0.11573841, ..., -0.80321172,\n",
    "         1.17646583, -0.86530163],\n",
    "       [-0.41500016, -0.48772236,  0.11573841, ..., -0.80321172,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.- Import `train_test_split` from `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.- Split the data into training and testing sets and save the results into four variables called `features_train`, `features_test`, `label_train`, and `label_test`. Use 10% of the data for testing and specify `random_state=8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.- Import `numpy` as np, `tensorflow` as tf, and `layers` from `tensorflow.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.- Set 8 as the seed for NumPy and TensorFlow using `np.random_seed()` and `tf.random.set_seed()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.- Instantantiate a `tf.keras.Sequential()` class and save it into a variable called `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.- Next, create a combined `l1` and `l2` regularizer using `tf.keras.regularizers.l1_l2` with `l1=0.01` and `l2=0.01`. Save it into a variable called `regularizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.- Instantantiate a `layers.Dense()` class with 10 neurons, `activation='relu'`, `input_shape=[12]`, and `kernel_regularizer=regularizer`, and save it into a variable called `layer1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.- Instantantiate a second `layers.Dense()` class with 1 neuron and save it into a variable called final_layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.- Add the two layers you just defined to the model using `.add()` and add a layer in between each of them with `layers.Dropout(0.25)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.- Instantantiate a `tf.keras.optimizers.SGD()` class with 0.001 as the learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.- Compile the neural network using `.compile()` with `loss='mse', optimizer=optimizer, metrics=['mse']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.- Print a summary of the model using `.summary()`\n",
    "\n",
    "Output:\n",
    "\n",
    "![Figure 6.16](img/fig6_16.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.- Instantiate a `tf.keras.callbacks.EarlyStopping()` class with `monitor='val_loss'` and `patience=2` as the learning rate and save it into a variable called `callback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just defined a callback stating the neural network will stop its training if the validation loss (`monitor='val_loss'`) does not improve after 2 epochs (`patience=2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21.- Fit the neural networks with the training set and specify `epochs=50, validation_split=0.2, callbacks=[callback]`, and `verbose=2`\n",
    "\n",
    "Output:\n",
    "\n",
    "![Figure 6.17](img/fig6_17.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, we see that the neural network stopped its training after the 22nd epoch. It stopped well before the maximum number of epochs, 50. This is due to the callback we set earlier: if the validation loss does not improve after two epochs, the training should stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
